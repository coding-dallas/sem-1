{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186be3d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assignment 2 - Question 1\n",
    "The objective of this assignment is to get you familiarize with  the  problem  of  `KNN Classifiers`.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "- Do not Use Direct Inbuilt functions for the Task.\n",
    "- Numpy or other math libraries are allowed \n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not change the contents of the Given cells. Use new cells to Write your code.\n",
    "\n",
    "\n",
    "## Submission\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Rename the notebook to `<roll_number>_Q1.ipynb`\n",
    "- Fill the Name and Roll number in the below markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6269f1",
   "metadata": {},
   "source": [
    "Name: Kesavaraj<br>\n",
    "Roll Number: 2022701008"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeabff5",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Use the code below to load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cac090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fa6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "#data cleaning\n",
    "iris.drop(columns=\"Id\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b822511-b320-4e08-8621-292751630349",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['Species']=iris['Species'].replace(['Iris-setosa','Iris-versicolor','Iris-virginica'],[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ca8135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features and labels\n",
    "X=iris.iloc[:,0:4].values\n",
    "y=iris.iloc[:,4].values\n",
    "\n",
    "#Train and Test split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14014cb",
   "metadata": {},
   "source": [
    "Write your Code below for KNN Classifier.<br>\n",
    "Use different values of K and test the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78cfa82c-c98d-44b1-8554-109c5e76b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ca8c19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Knn classifier\n",
    "class KNN:\n",
    "    def __init__(self,k):\n",
    "        self.k=k\n",
    "    \n",
    "    def similiarity(self,x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def training(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        \n",
    "        # Compute distances between x and all examples in the training set\n",
    "        distances = [self.similiarity(x, x_train) for x_train in self.X_train]\n",
    "        \n",
    "        # Sort by distance \n",
    "        k_index = np.argsort(distances)[: self.k]\n",
    "        \n",
    "        # k nearest neighbor training samples\n",
    "        nearest_labels = [self.y_train[i] for i in k_index]\n",
    "        \n",
    "        # return the most common class label\n",
    "        majority = Counter(nearest_labels).most_common(1)\n",
    "        return majority[0][0]\n",
    "    \n",
    "    def accuracy(y_true, y_pred):\n",
    "        acc = np.sum(y_true == y_pred) / len(y_true)\n",
    "        return acc\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5c018dd-755b-4c4f-b097-d96f5d3eeca6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KNN.similiarity() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m classifier \u001b[38;5;241m=\u001b[39m KNN(k\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m      6\u001b[0m classifier\u001b[38;5;241m.\u001b[39mtraining(X_train, y_train)\n\u001b[1;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m acc\u001b[38;5;241m.\u001b[39mappend([i,accuracy(y_test, predictions)])\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mKNN.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m---> 14\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m---> 14\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(y_pred)\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mKNN._predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     18\u001b[0m     \n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Compute distances between x and all examples in the training set\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimiliarity(x, x_train) \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train]\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Sort by distance \u001b[39;00m\n\u001b[0;32m     23\u001b[0m     k_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     18\u001b[0m     \n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Compute distances between x and all examples in the training set\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     distances \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimiliarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_train \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train]\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Sort by distance \u001b[39;00m\n\u001b[0;32m     23\u001b[0m     k_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n",
      "\u001b[1;31mTypeError\u001b[0m: KNN.similiarity() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    k_values=range(1,50,2)\n",
    "    acc=[]\n",
    "    for i in k_values:\n",
    "        classifier = KNN(k=i)\n",
    "        classifier.training(X_train, y_train)\n",
    "        predictions = classifier.predict(X_test)\n",
    "        acc.append([i,accuracy(y_test, predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ac0ca",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "1) What are the Advantages and Disadvantages of KNN algorithm?<br>\n",
    "2) What is the complexity of the KNN algorithm during Training and Testing?<br> \n",
    "3) Is euclidian distance the only distance metric used in KNN? \n",
    "4) what K value gave the best accuracy?\n",
    "\n",
    "### Answers\n",
    "1) Advantages:<br>\n",
    "No Training Period- KNN modeling does not include training period as the data itself is a model which will be the reference for future prediction    and because of this it is very time efficient in term of improvising for a random modeling on the available data<br>\n",
    "Easy Implementation- KNN is very easy to implement as the only thing to be calculated is the distance between different points on the basis of data of different features<br>\n",
    "Disadvantages:<br>\n",
    "Does not work well with large dataset as calculating distances between each data instance would be very costly.<br>\n",
    "Sensitive to noisy and missing data<br>\n",
    "\n",
    "2)\n",
    "The time complexity of the kNN algorithm is O(nd); n is the total number of data-points in the training data and d is the total number of features in the dataset.\n",
    "All distances will be computed for a new query point.\n",
    "\n",
    "3)No. Following are the some other distance measures<br>\n",
    "Minkowski<br>\n",
    "Manhattan<br>\n",
    "Cosine<br>\n",
    "\n",
    "4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47958869",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
